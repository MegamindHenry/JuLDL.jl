var documenterSearchIndex = {"docs":
[{"location":"man/make_adjacency_matrix/","page":"Make Adjacency Matrix","title":"Make Adjacency Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_adjacency_matrix/#Make-Adjacency-Matrix","page":"Make Adjacency Matrix","title":"Make Adjacency Matrix","text":"","category":"section"},{"location":"man/make_adjacency_matrix/","page":"Make Adjacency Matrix","title":"Make Adjacency Matrix","text":"  make_adjacency_matrix\n  make_adjacency_matrix(::Dict)","category":"page"},{"location":"man/make_adjacency_matrix/#JudiLing.make_adjacency_matrix","page":"Make Adjacency Matrix","title":"JudiLing.make_adjacency_matrix","text":"make fulladjacency matrix\n\n\n\n\n\n","category":"function"},{"location":"man/make_adjacency_matrix/#JudiLing.make_adjacency_matrix-Tuple{Dict}","page":"Make Adjacency Matrix","title":"JudiLing.make_adjacency_matrix","text":"makeadjacencymatrix(::Dict)\n\nMake full adjacency matrix based only on the form of n-grams regardless whether  they are seen in the training data. This usually takes hours for large dataset.\n\n...\n\nArguments\n\ntokenized::Bool=false: whether n-grams are tokenized\nsep_token::Union{Nothing, String, Char}=nothing: what is the sepertate token\nverbose::Bool=false: if verbose, more information prints out\n\nExamples\n\ni2f = Dict([(1, \"#ab\"), (2, \"abc\"), (3, \"bc#\"), (4, \"#bc\"), (5, \"ab#\")])\nJudiLing.make_adjacency_matrix(i2f)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/eval/","page":"Evaluation","title":"Evaluation","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/eval/#Find-Paths","page":"Evaluation","title":"Find Paths","text":"","category":"section"},{"location":"man/eval/","page":"Evaluation","title":"Evaluation","text":"  accuracy_comprehension\n  eval_SC\n  eval_acc(::Array, ::Array)\n  eval_acc_loose(::Array, ::Array)\n  eval_gpi\n  eval_manual","category":"page"},{"location":"man/eval/#JudiLing.accuracy_comprehension","page":"Evaluation","title":"JudiLing.accuracy_comprehension","text":"accuracy_comprehension(::Matrix, ::Matrix)\n\nEvaluate the comprehension accuracy\n\n...\n\nArguments\n\ntarget_col::Union{String, Symbol}=:Words: target column name\nbase::Vector=[\"Lexeme\"]: base features\ninflections::Union{Nothing, Vector}=nothing: inflective features\n\nExamples\n\nlatin_train = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\ncue_obj_train = JudiLing.make_cue_matrix(\n  latin_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nlatin_val = latin_train[101:150,:]\ncue_obj_val = JudiLing.make_cue_matrix(\n  latin_val,\n  cue_obj_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nn_features = size(cue_obj_train.C, 2)\n\nS_train, S_val = JudiLing.make_S_matrix(\n  latin_train,\n  latin_val,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=n_features)\n\nG_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C)\n\nChat_train = S_train * G_train\nChat_val = S_val * G_train\nJudiLing.eval_SC(cue_obj_train.C, Chat_train)\nJudiLing.eval_SC(cue_obj_val.C, Chat_val)\n\nF_train = JudiLing.make_transform_matrix(cue_obj_train.C, S_train)\n\nShat_train = cue_obj_train.C * F_train\nShat_val = cue_obj_val.C * F_train\nJudiLing.eval_SC(S_train, Shat_train)\nJudiLing.eval_SC(S_val, Shat_val)\n\naccuracy_comprehension(\n  S_train,\n  Shat_train,\n  latin_val,\n  target_col=:Words,\n  base=[\"Lexeme\"],\n  inflections=[\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"]\n  )\n\naccuracy_comprehension(\n  S_val,\n  Shat_val,\n  latin_train,\n  target_col=:Words,\n  base=[\"Lexeme\"],\n  inflections=[\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"]\n  )\n\n...\n\n\n\n\n\n","category":"function"},{"location":"man/eval/#JudiLing.eval_SC","page":"Evaluation","title":"JudiLing.eval_SC","text":"eval_SC(Union{SparseMatrixCSC, Matrix}, Union{SparseMatrixCSC, Matrix})\n\nevaluate S and Shat or C and Chat\n\n...\n\nExamples\n\n#after you had Shat and Chat\neval_SC(cue_obj_train.C, Chat_train)\neval_SC(cue_obj_val.C, Chat_val)\neval_SC(S_train, Shat_train)\neval_SC(S_val, Shat_val)\n\n...\n\n\n\n\n\n","category":"function"},{"location":"man/eval/#JudiLing.eval_acc-Tuple{Array,Array}","page":"Evaluation","title":"JudiLing.eval_acc","text":"eval_acc(::Array, ::Array)\n\nEvaluate the outputs from learnpaths function or buildpaths function\n\n...\n\nArguments\n\nverbose::Bool=false: if verbose, more information prints out\n\nExamples\n\n#after you had results from learn_paths or build_paths\nacc_train = JudiLing.eval_acc(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\nacc_val = JudiLing.eval_acc(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/eval/#JudiLing.eval_acc_loose-Tuple{Array,Array}","page":"Evaluation","title":"JudiLing.eval_acc_loose","text":"evalaccloose(::Array, ::Array)\n\nEvaluate the outputs from learnpaths function or buildpaths function, if one of the candidates are correct, then we take it correct. This reflects how many paths we could found but we could not recogni\n\n...\n\nArguments\n\nverbose::Bool=false: if verbose, more information prints out\n\nExamples\n\n#after you had results from learn_paths or build_paths\nacc_train_loose = JudiLing.eval_acc_loose(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\nacc_val_loose = JudiLing.eval_acc_loose(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/eval/#JudiLing.eval_gpi","page":"Evaluation","title":"JudiLing.eval_gpi","text":"Evaluate gold path info\n\n\n\n\n\n","category":"function"},{"location":"man/eval/#JudiLing.eval_manual","page":"Evaluation","title":"JudiLing.eval_manual","text":"Manually check the results\n\n\n\n\n\n","category":"function"},{"location":"man/all_manual/","page":"All Manual index","title":"All Manual index","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/all_manual/","page":"All Manual index","title":"All Manual index","text":"","category":"page"},{"location":"man/find_path/","page":"Find Paths","title":"Find Paths","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/find_path/#Find-Paths","page":"Find Paths","title":"Find Paths","text":"","category":"section"},{"location":"man/find_path/","page":"Find Paths","title":"Find Paths","text":"  Result_Path_Info_Struct\n  Gold_Path_Info_Struct\n  learn_paths\n  build_paths\n  learn_paths(::DataFrame,::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict)\n  build_paths(::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict,::Array)\n  eval_can(::Vector{Vector{Tuple{Vector{Integer}, Integer}}},::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Dict,::Integer,::Bool)\n  find_top_feature_indices(::Matrix, ::Array)","category":"page"},{"location":"man/find_path/#JudiLing.Result_Path_Info_Struct","page":"Find Paths","title":"JudiLing.Result_Path_Info_Struct","text":"store paths information found by learnpaths or buildpaths function\n\n\n\n\n\n","category":"type"},{"location":"man/find_path/#JudiLing.Gold_Path_Info_Struct","page":"Find Paths","title":"JudiLing.Gold_Path_Info_Struct","text":"store gold paths information including indices and indices support and total support it can be used to evaluate how low the threshold is set in order to find the correct paths\n\n\n\n\n\n","category":"type"},{"location":"man/find_path/#JudiLing.learn_paths","page":"Find Paths","title":"JudiLing.learn_paths","text":"learnpaths function takes each timestep individually and calculate Ythat respectively,\n\n\n\n\n\n","category":"function"},{"location":"man/find_path/#JudiLing.build_paths","page":"Find Paths","title":"JudiLing.build_paths","text":"build_paths function is shortcut algorithms that only takes n-grams that closed to the validation data\n\n\n\n\n\n","category":"function"},{"location":"man/find_path/#JudiLing.learn_paths-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,SparseArrays.SparseMatrixCSC,Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Array{T,2} where T,SparseArrays.SparseMatrixCSC,Dict}","page":"Find Paths","title":"JudiLing.learn_paths","text":"learn_paths(::DataFrame,::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict)\n\nlearnpaths function takes each timestep individually and calculate Ythat respectively,\n\n...\n\nArguments\n\ngold_ind::Union{Nothing, Vector}=nothing: for in goldpathinfo mode\nShat_val::Union{Nothing, Matrix}=nothing: for goldpathinfo mode\ncheck_gold_path::Bool=false: if turn on goldpathinfo mode\nmax_t::Integer=15: maximum timestep\nmax_can::Integer=10: maximum candidates when output\nthreshold::AbstractFloat=0.1: for each timestep, only grams greater than threshold will be selected\nis_tolerant::Bool=false: if in tolerant mode, path allows limited nodes under threshold but greater than tolerance\ntolerance::AbstractFloat=(-1000.0): in tolerant mode, only nodes greater than tolerance and lesser than threshold will be selected\nmax_tolerance::Integer=4: maximum numbers of nodes allowed in a path\ngrams::Integer=3: n-grams\ntokenized::Bool=false: whether tokenized\nsep_token::Union{Nothing, String, Char}=nothing: seperate token\nkeep_sep::Bool=false: whether keep seperaters in grams\ntarget_col::Union{String, :Symbol}=:Words: word column names\nissparse::Symbol=:auto: mt matrix output format mode\nverbose::Bool=false: if verbose, more information will be printed out\n\nExamples\n\nlatin_train = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\ncue_obj_train = JudiLing.make_cue_matrix(\n  latin_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nlatin_val = latin_train[101:150,:]\ncue_obj_val = JudiLing.make_cue_matrix(\n  latin_val,\n  cue_obj_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nn_features = size(cue_obj_train.C, 2)\n\nS_train, S_val = JudiLing.make_S_matrix(\n  latin_train,\n  latin_val,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=n_features)\n\nG_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C)\n\nChat_train = S_train * G_train\nChat_val = S_val * G_train\n\nF_train = JudiLing.make_transform_matrix(cue_obj_train.C, S_train)\n\nShat_train = cue_obj_train.C * F_train\nShat_val = cue_obj_val.C * F_train\n\nA = cue_obj_train.A\n\nmax_t = JudiLing.cal_max_timestep(latin_train, latin_val, :Word)\n\nres_train, gpi_train = JudiLing.learn_paths(\n  latin_train,\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  gold_ind=cue_obj_train.gold_ind,\n  Shat_val=Shat_train,\n  check_gold_path=true,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  sep_token=\"_\",\n  keep_sep=false,\n  target_col=:Word,\n  issparse=:dense,\n  verbose=false)\n\nres_val, gpi_val = JudiLing.learn_paths(\n  latin_train,\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  gold_ind=cue_obj_val.gold_ind,\n  Shat_val=Shat_val,\n  check_gold_path=true,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  is_tolerant=true,\n  tolerance=0.1,\n  max_tolerance=0,\n  tokenized=false,\n  sep_token=\"-\",\n  keep_sep=false,\n  target_col=:Word,\n  issparse=:dense,\n  verbose=false)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/find_path/#JudiLing.build_paths-Tuple{DataFrames.DataFrame,SparseArrays.SparseMatrixCSC,Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Array{T,2} where T,SparseArrays.SparseMatrixCSC,Dict,Array}","page":"Find Paths","title":"JudiLing.build_paths","text":"build_paths(::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict,::Array)\n\nbuild_paths function is shortcut algorithms that only takes n-grams that closed to the validation data\n\n...\n\nArguments\n\nrC::Union{Nothing, Matrix}=nothing: correlation Matrix of C and Chat, passing it to save computing time\nmax_t::Integer=15: maximum timestep\nmax_can::Integer=10: maximum candidates when output\nn_neighbors::Integer=10: find indices only in top n neighbors\ngrams::Integer=3: n-grams\ntokenized::Bool=false: whether tokenized\nsep_token::Union{Nothing, String, Char}=nothing: seperate token\ntarget_col::Union{String, :Symbol}=:Words: word column names\nverbose::Bool=false: if verbose, more information will be printed out\n\nExamples\n\nlatin_train = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\ncue_obj_train = JudiLing.make_cue_matrix(\n  latin_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nlatin_val = latin_train[101:150,:]\ncue_obj_val = JudiLing.make_cue_matrix(\n  latin_val,\n  cue_obj_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nn_features = size(cue_obj_train.C, 2)\n\nS_train, S_val = JudiLing.make_S_matrix(\n  latin_train,\n  latin_val,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=n_features)\n\nG_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C)\n\nChat_train = S_train * G_train\nChat_val = S_val * G_train\n\nF_train = JudiLing.make_transform_matrix(cue_obj_train.C, S_train)\n\nShat_train = cue_obj_train.C * F_train\nShat_val = cue_obj_val.C * F_train\n\nA = cue_obj_train.A\n\nmax_t = JudiLing.cal_max_timestep(latin_train, latin_val, :Word)\n\nJudiLing.build_paths(\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=10,\n  verbose=false\n  )\n\nJudiLing.build_paths(\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=10,\n  verbose=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/find_path/#JudiLing.eval_can-Tuple{Array{Array{Tuple{Array{Integer,1},Integer},1},1},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Dict,Integer,Bool}","page":"Find Paths","title":"JudiLing.eval_can","text":"eval_can(::Vector{Vector{Tuple{Vector{Integer}, Integer}}},::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Dict,::Integer,::Bool)\n\nat the end of finding path algorithms, each candidates need to be evaluated regarding their predicted semantic vectors\n\n\n\n\n\n","category":"method"},{"location":"man/find_path/#JudiLing.find_top_feature_indices-Tuple{Array{T,2} where T,Array}","page":"Find Paths","title":"JudiLing.find_top_feature_indices","text":"findtopfeature_indices(::Matrix, ::Array)\n\nfind out all indices within the closed top n datarow for a given validation datarow\n\n\n\n\n\n","category":"method"},{"location":"man/make_yt_matrix/","page":"Make Yt Matrix","title":"Make Yt Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_yt_matrix/#Make-Yt-Matrix","page":"Make Yt Matrix","title":"Make Yt Matrix","text":"","category":"section"},{"location":"man/make_yt_matrix/","page":"Make Yt Matrix","title":"Make Yt Matrix","text":"  make_Yt_matrix\n  make_Yt_matrix(::Integer, ::DataFrame)","category":"page"},{"location":"man/make_yt_matrix/#JudiLing.make_Yt_matrix","page":"Make Yt Matrix","title":"JudiLing.make_Yt_matrix","text":"make Y matrix given timestep t\n\n\n\n\n\n","category":"function"},{"location":"man/make_yt_matrix/#JudiLing.make_Yt_matrix-Tuple{Integer,DataFrames.DataFrame}","page":"Make Yt Matrix","title":"JudiLing.make_Yt_matrix","text":"makeYtmatrix(::Integer, ::DataFrame)\n\nMake full adjacency matrix based only on the form of n-grams regardless whether  they are seen in the training data. This usually takes hours for large dataset.\n\n...\n\nArguments\n\ntokenized::Bool=false: whether n-grams are tokenized\nsep_token::Union{Nothing, String, Char}=nothing: what is the sepertate token\nverbose::Bool=false: if verbose, more information prints out\n\nExamples\n\nlatin = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\nJudiLing.make_Yt_matrix(2, latin)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/","page":"Cholesky","title":"Cholesky","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/cholesky/#Cholesky","page":"Cholesky","title":"Cholesky","text":"","category":"section"},{"location":"man/cholesky/","page":"Cholesky","title":"Cholesky","text":"  make_transform_fac\n  make_transform_matrix\n  make_transform_fac(::SparseMatrixCSC)\n  make_transform_fac(::Matrix)\n  make_transform_matrix(::Union{LinearAlgebra.Cholesky, SuiteSparse.CHOLMOD.Factor}, ::Union{SparseMatrixCSC, Matrix}, ::Union{SparseMatrixCSC, Matrix})\n  make_transform_matrix(::SparseMatrixCSC, ::Matrix)\n  make_transform_matrix(::Matrix, ::Union{SparseMatrixCSC, Matrix})\n  make_transform_matrix(::SparseMatrixCSC, ::SparseMatrixCSC)\n  format_matrix(::Union{SparseMatrixCSC, Matrix}, ::Symbol, ::Bool)","category":"page"},{"location":"man/cholesky/#JudiLing.make_transform_fac","page":"Cholesky","title":"JudiLing.make_transform_fac","text":"the first part of make transform matrix, usually in the learn_paths function to same time and computing resources\n\n\n\n\n\n","category":"function"},{"location":"man/cholesky/#JudiLing.make_transform_matrix","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"using cholesky decomposition to calculate transformation matrix from S to C or from C to S\n\n\n\n\n\n","category":"function"},{"location":"man/cholesky/#JudiLing.make_transform_fac-Tuple{SparseArrays.SparseMatrixCSC}","page":"Cholesky","title":"JudiLing.make_transform_fac","text":"maketransformfac(::SparseMatrixCSC)\n\ncalculate first part of cholesky decomposition for sparse matrix\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_fac-Tuple{Array{T,2} where T}","page":"Cholesky","title":"JudiLing.make_transform_fac","text":"maketransformfac(::Matrix)\n\ncalculate first part of cholesky decomposition for dense matrix\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{Union{SuiteSparse.CHOLMOD.Factor, LinearAlgebra.Cholesky},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC}}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"maketransformmatrix(::Union{LinearAlgebra.Cholesky, SuiteSparse.CHOLMOD.Factor}, ::Union{SparseMatrixCSC, Matrix}, ::Union{SparseMatrixCSC, Matrix})\n\nsecond part of calculate cholesky decomposition transformation matrix\n\n...\n\nArguments\n\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nverbose::Bool=false: if verbose, more information will be printed out\n\nExamples\n\n  C = [1 1 1 1 0 0 0 0; 1 0 1 0 1 0 1 0; 0 0 0 0 1 1 1 1]\n  S = [1 0 1 0; 1 1 0 0; 0 0 1 1]\n\n  JudiLing.make_transform_matrix(C, S)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{SparseArrays.SparseMatrixCSC,Array{T,2} where T}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"maketransformmatrix(::SparseMatrixCSC, ::Matrix)\n\nusing cholesky decomposition to calculate transformation matrix from X to Y, where X is a sparse matrix and Y is a dense matrix\n\n...\n\nArguments\n\nmethod::Symbol=:additive: shift mode whether :additive or others\nshift::AbstractFloat=0.02: shift value\nmultiplier::AbstractFloat=1.01: multiplier value\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nverbose::Bool=false: if verbose, more information will be printed out\n\nExamples\n\n  C = [1 1 1 1 0 0 0 0; 1 0 1 0 1 0 1 0; 0 0 0 0 1 1 1 1]\n  S = [1 0 1 0; 1 1 0 0; 0 0 1 1]\n\n  JudiLing.make_transform_matrix(C, S)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{Array{T,2} where T,Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC}}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"maketransformmatrix(::Matrix, ::Union{SparseMatrixCSC, Matrix})\n\nusing cholesky decomposition to calculate transformation matrix from X to Y, where X is a dense matrix and Y is either a dense matrix or a sparse matrix\n\n...\n\nArguments\n\nmethod::Symbol=:additive: shift mode whether :additive or others\nshift::AbstractFloat=0.02: shift value\nmultiplier::AbstractFloat=1.01: multiplier value\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nverbose::Bool=false: if verbose, more information will be printed out\n\nExamples\n\n  C = [1 1 1 1 0 0 0 0; 1 0 1 0 1 0 1 0; 0 0 0 0 1 1 1 1]\n  S = [1 0 1 0; 1 1 0 0; 0 0 1 1]\n\n  JudiLing.make_transform_matrix(C, S)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{SparseArrays.SparseMatrixCSC,SparseArrays.SparseMatrixCSC}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"maketransformmatrix(::SparseMatrixCSC, ::SparseMatrixCSC)\n\nusing cholesky decomposition to calculate transformation matrix from X to Y, where X is a sparse matrix and Y is a sparse matrix\n\n...\n\nArguments\n\nmethod::Symbol=:additive: shift mode whether :additive or others\nshift::AbstractFloat=0.02: shift value\nmultiplier::AbstractFloat=1.01: multiplier value\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nverbose::Bool=false: if verbose, more information will be printed out\n\nExamples\n\n  C = [1 1 1 1 0 0 0 0; 1 0 1 0 1 0 1 0; 0 0 0 0 1 1 1 1]\n  S = [1 0 1 0; 1 1 0 0; 0 0 1 1]\n\n  JudiLing.make_transform_matrix(C, S)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.format_matrix-Tuple{Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Symbol,Bool}","page":"Cholesky","title":"JudiLing.format_matrix","text":"format_matrix(::Union{SparseMatrixCSC, Matrix}, ::Symbol, ::Bool)\n\nconvert ourput matrix to a dense matrix or sparse matrix\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/","page":"Make Semantic Matrix","title":"Make Semantic Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_semantic_matrix/#Make-Semantic-Matrix","page":"Make Semantic Matrix","title":"Make Semantic Matrix","text":"","category":"section"},{"location":"man/make_semantic_matrix/","page":"Make Semantic Matrix","title":"Make Semantic Matrix","text":"  PS_Matrix_Struct\n  make_pS_matrix\n  make_S_matrix\n  make_pS_matrix(::DataFrame)\n  make_pS_matrix(::DataFrame, ::PS_Matrix_Struct)\n  make_S_matrix(::DataFrame, ::Vector, ::Vector)\n  make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::Vector)\n  make_S_matrix(::DataFrame)\n  make_S_matrix(::DataFrame, ::DataFrame)","category":"page"},{"location":"man/make_semantic_matrix/#JudiLing.PS_Matrix_Struct","page":"Make Semantic Matrix","title":"JudiLing.PS_Matrix_Struct","text":"This a struct that store all information about prelinguistic and their feature indices. pS is the cue matrix f2i is the dictionary return indices giving features i2f is in another hand return features when giving indices\n\n\n\n\n\n","category":"type"},{"location":"man/make_semantic_matrix/#JudiLing.make_pS_matrix","page":"Make Semantic Matrix","title":"JudiLing.make_pS_matrix","text":"This is the function that make prelinguistic semantic matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"This is the function that make simulated semantic matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_semantic_matrix/#JudiLing.make_pS_matrix-Tuple{DataFrames.DataFrame}","page":"Make Semantic Matrix","title":"JudiLing.make_pS_matrix","text":"makepSmatrix(::DataFrame)\n\nThis is a function that create prelinguistic matrix giving a csv file.\n\n...\n\nArguments\n\nfeatures_col::Symbol=:CommunicativeIntention: the column name for communicative intention\nsep_token::String=\"_\": the seperated token in the communicative intention column\n\nExamples\n\nutterance = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"utterance_mini.csv\")))\ns_obj_train = JudiLing.make_pS_matrix(utterance)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_pS_matrix-Tuple{DataFrames.DataFrame,JudiLing.PS_Matrix_Struct}","page":"Make Semantic Matrix","title":"JudiLing.make_pS_matrix","text":"makepSmatrix(::DataFrame, PSMatrixStruct)\n\nThis is a function that construct prelinguistic matrix giving utterances and training sobj. The feature indices should maintain the same as thoes in sobj.\n\n...\n\nArguments\n\nfeatures_col::Symbol=:CommunicativeIntention: the column name for communicative intention\nsep_token::String=\"_\": the seperated token in the communicative intention column\n\nExamples\n\nutterance = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"utterance_mini.csv\")))\ns_obj_train = JudiLing.make_pS_matrix(utterance)\ns_obj_val = JudiLing.make_pS_matrix(utterance_val, s_obj_train)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"makeSmatrix(::DataFrame, ::Vector, ::Vector)\n\nThis is a function that create simulated semantic matrix. Give each feature a random semantic vector, and sum up all features to compose the semantic vector.\n\n...\n\nArguments\n\nncol::Integer=200: the dimension size of vectors, usually the same as cue vectors\nsd_base_mean::Integer=1: the sd mean of base features\nsd_inflection_mean::Integer=1: the sd mean of inflectional features\nsd_base::Integer=4: the sd of base features\nsd_inflection::Integer=4: the sd of inflectional features\nseed::Integer=314: the random seed\nisdeep::Bool=true: if in deep mode, mean of each feature is also randomized \nadd_noise::Bool=true: whether to add noise at the end of construction\nsd_noise::Integer=1: the sd of the noise matrix\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may exceeds 1 or -1 depending on the sd\n\nExamples\n\n# Examples\nfrench = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"french_mini.csv\")))\nS_train = JudiLing.make_S_matrix(\n  french,\n  [\"Lexeme\"],\n  [\"Tense\",\"Aspect\",\"Person\",\"Number\",\"Gender\",\"Class\",\"Mood\"])\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"makeSmatrix(::DataFrame, ::DataFrame, ::Vector, ::Vector)\n\nThis is a function that create validation simulated semantic matrix. Give each feature a random semantic vector, and sum up all features to compose the semantic vector.\n\n...\n\nArguments\n\nncol::Integer=200: the dimension size of vectors, usually the same as cue vectors\nsd_base_mean::Integer=1: the sd mean of base features\nsd_inflection_mean::Integer=1: the sd mean of inflectional features\nsd_base::Integer=4: the sd of base features\nsd_inflection::Integer=4: the sd of inflectional features\nseed::Integer=314: the random seed\nisdeep::Bool=true: if in deep mode, mean of each feature is also randomized \nadd_noise::Bool=true: whether to add noise at the end of construction\nsd_noise::Integer=1: the sd of the noise matrix\nnormalized::Bool=false: if normalized, values of matrix maintain close between 1 and -1\n\nExamples\n\n# Examples\nfrench = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"french_mini.csv\")))\nfrench_val = french[100:end,:]\nS_train, S_val = JudiLing.make_S_matrix(\n    french,\n    french_val,\n    [\"Lexeme\"],\n    [\"Tense\",\"Aspect\",\"Person\",\"Number\",\"Gender\",\"Class\",\"Mood\"])\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"makeSmatrix(::DataFrame)\n\nThis is a function that create simulated semantic matrix, provided for dataset that only have base features. Give each feature a random semantic vector, and sum up all features to compose the semantic vector.\n\n...\n\nArguments\n\nbase::Vector=[\"Lexeme\"]: the base features \nncol::Integer=200: the dimension size of vectors, usually the same as cue vectors\nsd_base_mean::Integer=1: the sd mean of base features\nsd_base::Integer=4: the sd of base features\nseed::Integer=314: the random seed\nisdeep::Bool=true: if in deep mode, mean of each feature is also randomized \nadd_noise::Bool=true: whether to add noise at the end of construction\nsd_noise::Integer=1: the sd of the noise matrix\n\nExamples\n\nfrench = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"french_mini.csv\")))\n\nS_train = JudiLing.make_S_matrix(\n  french,\n  base=[\"Lexeme\"])=\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"makeSmatrix(::DataFrame, ::DataFrame)\n\nThis is a function that create validation simulated semantic matrix, provided for dataset that only have base features. Give each feature a random semantic vector, and sum up all features to compose the semantic vector.\n\n...\n\nArguments\n\nbase::Vector=[\"Lexeme\"]: the base features \nncol::Integer=200: the dimension size of vectors, usually the same as cue vectors\nsd_base_mean::Integer=1: the sd mean of base features\nsd_base::Integer=4: the sd of base features\nseed::Integer=314: the random seed\nisdeep::Bool=true: if in deep mode, mean of each feature is also randomized \nadd_noise::Bool=true: whether to add noise at the end of construction\nsd_noise::Integer=1: the sd of the noise matrix\n\nExamples\n\nfrench = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"french_mini.csv\")))\nfrench_val = french[100:end,:]\nS_train, S_val = JudiLing.make_S_matrix(\n    french,\n    french_val,\n    base=[\"Lexeme\"])\n\n...\n\n\n\n\n\n","category":"method"},{"location":"#JudiLing","page":"Home","title":"JudiLing","text":"","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JudiLing can be installed using the Julia package manager via GitHub HTTPS Links. From the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/MegamindHenry/JudiLing.jl.git","category":"page"},{"location":"#Examples","page":"Home","title":"Examples","text":"","category":"section"},{"location":"#Latin","page":"Home","title":"Latin","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let's look at our first real dataset example. latin.csv contains lexemes and inflective features about Latin verbs.","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\",\"Word\",\"Lexeme\",\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"\n\"1\",\"vocoo\",\"vocare\",\"p1\",\"sg\",\"present\",\"active\",\"ind\"\n\"2\",\"vocaas\",\"vocare\",\"p2\",\"sg\",\"present\",\"active\",\"ind\"\n\"3\",\"vocat\",\"vocare\",\"p3\",\"sg\",\"present\",\"active\",\"ind\"\n\"4\",\"vocaamus\",\"vocare\",\"p1\",\"pl\",\"present\",\"active\",\"ind\"\n\"5\",\"vocaatis\",\"vocare\",\"p2\",\"pl\",\"present\",\"active\",\"ind\"\n\"6\",\"vocant\",\"vocare\",\"p3\",\"pl\",\"present\",\"active\",\"ind\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Before we start, we first need to add two packages in julia by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using JudiLing # our package\nusing CSV # read csv files into dataframes","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, we need to read csv file by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"latin_train = CSV.DataFrame!(CSV.File(joinpath(@__DIR__, \"data\", \"latin.csv\")))","category":"page"},{"location":"","page":"Home","title":"Home","text":"and here we simulate our validation csv file, where contain the same lexemes and inflective features and cues.","category":"page"},{"location":"","page":"Home","title":"Home","text":"latin_val = latin_train[101:150,:]","category":"page"},{"location":"","page":"Home","title":"Home","text":"warning: Warning\nThe real validation dataset should NOT contains datarows in the training dataset.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For production model, we want to predict correct forms given their lexemes and inflective features. For example, giving the lexeme vocare and its inflective features p1, sg, present, active and ind, the model should be able to produce the form vocoo. On the other hand, the comprehension model takes forms as input and try to predict theirs lexemes and inflective features.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We use letter n-grams to encode our forms. For word vocoo, for example, we encode it as #vo, voc, oco, coo and oo#. Here, # is used as start/end token to encode the beginning and ending of a word. To make the C matrix, we use:","category":"page"},{"location":"","page":"Home","title":"Home","text":"cue_obj_train = JudiLing.make_cue_matrix(\n  latin_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )","category":"page"},{"location":"","page":"Home","title":"Home","text":"In order to maintain the same indices as in the training C matrix, we need to pass it when we construct validation C matrix.","category":"page"},{"location":"","page":"Home","title":"Home","text":"cue_obj_val = JudiLing.make_cue_matrix(\n  latin_val,\n  cue_obj_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, we can simulate our training and validation S matrices by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"n_features = size(cue_obj_train.C, 2)\nS_train, S_val = JudiLing.make_S_matrix(\n  latin_train,\n  latin_val,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=n_features)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For this simulation, random vectors are assigned to every lexemes and inflective features and we sum up add lexemes and features as our semantic vector for each word entry. As our studies shown, similar dimensions between C and S work the best. Thus, we retrieve dimension from C matrix and pass it to construct S matrix.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, the next step is to calculate mapping from S to C by solving equation C = SG. We have several mapping mode, but here we use cholesky decomposition mode to solve the equation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"G_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, we can make our predicted C matrix Chat by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Chat_train = S_train * G_train\nChat_val = S_val * G_train","category":"page"},{"location":"","page":"Home","title":"Home","text":"and we can evaluate our prediction by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@show JudiLing.eval_SC(cue_obj_train.C, Chat_train)\n@show JudiLing.eval_SC(cue_obj_val.C, Chat_val)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Similar to G and Chat, we can solve S = CF by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"F_train = JudiLing.make_transform_matrix(cue_obj_train.C, S_train)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and we can predict Shat matrices and evaluate them:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Shat_train = cue_obj_train.C * F_train\nShat_val = cue_obj_val.C * F_train\n\n@show JudiLing.eval_SC(S_train, Shat_train)\n@show JudiLing.eval_SC(S_val, Shat_val)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We have path finding algorithm to further predict the forms in a sequence. The first step is to construct adjacency matrix. Here we use adjacency constructed inside makecuematrix(), but we can also make a full adjacency matrix if we need.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = cue_obj_train.A","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, we calculate how timesteps do we need for our learning function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"max_t = JudiLing.cal_max_timestep(latin_train, latin_val, :Word)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, we make to our path finding function to predict forms in a sequence.","category":"page"},{"location":"","page":"Home","title":"Home","text":"res_train, gpi_train = JudiLing.learn_paths(\n  latin_train,\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  gold_ind=cue_obj_train.gold_ind,\n  Shat_val=Shat_train,\n  check_gold_path=true,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  sep_token=\"_\",\n  keep_sep=false,\n  target_col=:Word,\n  issparse=:dense,\n  verbose=true)\n\nres_val, gpi_val = JudiLing.learn_paths(\n  latin_train,\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  gold_ind=cue_obj_val.gold_ind,\n  Shat_val=Shat_val,\n  check_gold_path=true,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  is_tolerant=true,\n  tolerance=-0.1,\n  max_tolerance=2,\n  tokenized=false,\n  sep_token=\"-\",\n  keep_sep=false,\n  target_col=:Word,\n  issparse=:dense,\n  verbose=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and we evaluate our results:","category":"page"},{"location":"","page":"Home","title":"Home","text":"acc_train = JudiLing.eval_acc(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\nacc_val = JudiLing.eval_acc(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\nprintln(\"Acc for train: $acc_train\")\nprintln(\"Acc for val: $acc_val\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can download and try our completed script.","category":"page"},{"location":"man/make_cue_matrix/","page":"Make Cue Matrix","title":"Make Cue Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_cue_matrix/#Make-Cue-Matrix","page":"Make Cue Matrix","title":"Make Cue Matrix","text":"","category":"section"},{"location":"man/make_cue_matrix/","page":"Make Cue Matrix","title":"Make Cue Matrix","text":"  Cue_Matrix_Struct\r\n  make_cue_matrix\r\n  make_ngrams\r\n  make_cue_matrix(::DataFrame)\r\n  make_cue_matrix(::DataFrame,::Cue_Matrix_Struct)\r\n  make_ngrams(::Array,::Int64,::Bool,::Union{Nothing, String, Char},::Union{String, Char})","category":"page"},{"location":"man/make_cue_matrix/#JudiLing.Cue_Matrix_Struct","page":"Make Cue Matrix","title":"JudiLing.Cue_Matrix_Struct","text":"a struct that store info after makecuematrix C is the cue matrix f2i is the dictionary return indices giving features i2f is in another hand return features when giving indices gold_ind stores gold paths within a list of indices A is the adjacency matrix\n\n\n\n\n\n","category":"type"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"Construct cue matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_cue_matrix/#JudiLing.make_ngrams","page":"Make Cue Matrix","title":"JudiLing.make_ngrams","text":"Given tokens make n-grams.\n\n\n\n\n\n","category":"function"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix-Tuple{DataFrames.DataFrame}","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"makecuematrix(::DataFrame)\n\nThis function makes cue matrix and corresponding indices given dataset as csv file.\n\n...\n\nArguments\n\ngrams::Integer=3: the number of grams for cues \ntarget_col::Union{String, Symbol}=:Words: the column name for target\ntokenized::Bool=false: whether the word is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: what is the seperate token\nkeep_sep::Bool=false: whether to keep seperater in cues\nstart_end_token::Union{String, Char}=\"#\": start and end token\nverbose::Bool=false: if verbose, more information prints out\n\nExamples\n\nlatin = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\nlatin_cue_obj_train = JudiLing.make_cue_matrix(\n  latin,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix-Tuple{DataFrames.DataFrame,JudiLing.Cue_Matrix_Struct}","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"makecuematrix(::DataFrame,::CueMatrixStruct)\n\nThis function make cue matrix and corresponding indices giving dataset as csv file and train dataset cue obj. This is often used to construct valcueobj, in order to maintain the same indices.\n\n...\n\nArguments\n\ngrams::Integer=3: the number of grams for cues \ntarget_col::Union{String, Symbol}=:Words: the column name for target\ntokenized::Bool=false: whether the word is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: what is the seperate token\nkeep_sep::Bool=false: whether to keep seperater in cues\nstart_end_token::Union{String, Char}=\"#\": start and end token\nverbose::Bool=false: if verbose, more information prints out\n\nExamples\n\nlatin = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\nlatin_cue_obj_train = JudiLing.make_cue_matrix(\n  latin,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n# simulate the val dataset. Notice here that latin_val is part of training dataset to make\n# sure all features and n-grams covered by training dataset.\nlatin_val = latin[101:150,:]\nlatin_cue_obj_val = JudiLing.make_cue_matrix(\n  latin_val,\n  latin_cue_obj_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_cue_matrix/#JudiLing.make_ngrams-Tuple{Array,Int64,Bool,Union{Nothing, Char, String},Union{Char, String}}","page":"Make Cue Matrix","title":"JudiLing.make_ngrams","text":"make_ngrams(::Array,::Integer,::Bool,   ::Union{Nothing, String, Char},::Union{String, Char}\n\ngiven a list of tokens, return all ngrams in a list\n\n\n\n\n\n","category":"method"},{"location":"man/utils/","page":"Utils","title":"Utils","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/utils/#Utils","page":"Utils","title":"Utils","text":"","category":"section"},{"location":"man/utils/","page":"Utils","title":"Utils","text":"  iscorrect\n  display_pred\n  translate\n  translate_path\n  is_truly_sparse\n  isattachable\n  iscomplete\n  isstart\n  isnovel\n  check_used_token\n  cal_max_timestep","category":"page"},{"location":"man/utils/#JudiLing.iscorrect","page":"Utils","title":"JudiLing.iscorrect","text":"check whether the prediction is correct\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.display_pred","page":"Utils","title":"JudiLing.display_pred","text":"display prediction nicely\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.translate","page":"Utils","title":"JudiLing.translate","text":"translate indices into words or utterances\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.translate_path","page":"Utils","title":"JudiLing.translate_path","text":"just append indices together\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.is_truly_sparse","page":"Utils","title":"JudiLing.is_truly_sparse","text":"check whether a matrix is truly sparse regardless its format\n\n\n\n\n\ncheck whether a matrix is truly sparse regardless its format\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.isattachable","page":"Utils","title":"JudiLing.isattachable","text":"check a gram is attach to another gram\n\n\n\n\n\ncheck a gram is attach to another gram\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.iscomplete","page":"Utils","title":"JudiLing.iscomplete","text":"check a gram could complete a path\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.isstart","page":"Utils","title":"JudiLing.isstart","text":"check a gram could start a path\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.isnovel","page":"Utils","title":"JudiLing.isnovel","text":"check wheter a path is in training data or nor\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.check_used_token","page":"Utils","title":"JudiLing.check_used_token","text":"check whether there are token used in dataset\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.cal_max_timestep","page":"Utils","title":"JudiLing.cal_max_timestep","text":"calculate max timestep given training and validation datasets\n\n\n\n\n\ncalculate max timestep given training dataset\n\n\n\n\n\n","category":"function"}]
}
